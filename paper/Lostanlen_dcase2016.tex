% --------------------------------------------------------------------------
% Template for DCASE 2016 paper; to be used with:
%          dcase2016.sty  - DCASE 2016 LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% Adapted from spconf.sty and waspaa15.sty
% --------------------------------------------------------------------------

\documentclass{article}
\usepackage{dcase2016,amsmath,graphicx,url,times}
\usepackage{booktabs}
%\usepackage{dcase2016,amssymb,amsmath,graphicx,times,url}

% Example definitions.
% --------------------
\def\defeqn{\stackrel{\triangle}{=}}
\newcommand{\symvec}[1]{{\mbox{\boldmath $#1$}}}
\newcommand{\symmat}[1]{{\mbox{\boldmath $#1$}}}

\newcommand{\la}{{\lambda}}
\newcommand{\lau}{{\lambda_1}}
\newcommand{\lad}{{\lambda_2}}

% Title.
% --------------------
\title{Binaural Scene Classification with Wavelet Scattering}

% Single addresses (uncomment and modify for single-address case).
% --------------------
%\name{Author(s) Name(s)\thanks{Thanks to XYZ agency for funding.}}
%\address{Author Affiliation(s)}
%
% For example:
% ------------
%\address{School\\
%       Department\\
%       Address}

% Two addresses
% --------------------
\twoauthors
  {Vincent Lostanlen}
    {D\'{e}partement d'Informatique \\ \'{E}cole normale sup\'{e}rieure \\ Paris, France \\
     vincent.lostanlen@ens.fr}
  {Joakim And\'{e}n\sthanks{This work is supported by the ERC InvariantClass grant 320959. The source code to reproduce figures and experiments is freely available at \protect\url{http://www.github.com/lostanlen/dcase2016}.}}
    {Program in Applied and Computational Mathematics \\ Princeton University \\
     Princeton, NJ, USA \\
     janden@math.princeton.edu}

\begin{document}

\ninept
\maketitle

\begin{sloppy}

\begin{abstract}
This technical report describes our contribution to the scene classification task of the 2016 IEEE AASP Challenge for Detection and Classification of Acoustic Scenes and Events (DCASE). Our computational pipeline consists of a Gammatone scattering transform, averaged at a time scale of 740 ms with logarithmic compression and frame-based classification using a linear support vector machine (SVM). At test time, decisions are aggregated over the whole recording by majority voting. We propose a novel data augmentation technique, where we mix the left and right channels in varying proportions in order to enforce invariance to azimuthal orientation of the binaural recording system.
\end{abstract}

\begin{keywords}
One, two, three, four, five
\end{keywords}

\section{System outline}
The system used for the scene classification task is illustrated in Figure \ref{fig:outline}. Each recording is decomposed using a time scattering transform, which provides a signal representation that is locally invariant to time-shifting and stable to time-warping deformation. Since small changes in timing have little relevance to the auditory scene of a particular recording, this invariance reduces the variability of the data without necessarily hampering discriminability. The averaging scale of the scattering transform is fixed to be $740~\mathrm{ms}$. In order to account for the varying orders of magnitude across frequencies, we then apply a logarithmic compression to the data. Each recording is thus represented as a sequence of logarithmically compressed scattering vectors.

At the training stage, a linear support vector machine (SVM) classifier is trained using the sequences obtained from the training data. For each recording in the testing set, the classifier is applied to all scattering vectors in the recording, yielding a class for each vector. The class of the entire recording is then determined by majority vote. Evaluating this system on the standard four train-test splits in the development data, we obtain an average accuracy of ???.

\section{Scattering transform}

The scattering transform was introduced by S. Mallat as a signal representation that is invariant to translations and stable to deformation \cite{stephane}. It has had success in classifying images \cite{joan}, audio \cite{dss}, and biomedical signals \cite{embs}. For audio signals, translation corresponds to time-shifting, while deforming a signal warps it in time. Both of these transformations have little to no effect on the semantic content of an audio signal, so reducing their influence enables us to train more accurate classifiers using limited training data. A brief review of the scattering transform is provided in this section.

\begin{figure}
\begin{center}
\setlength{\unitlength}{1cm}
\begin{picture}(5,2)
 \put(-1.5,0.0){\includegraphics[height=2cm,width=3.5cm]{gammatone_Q4.png}}
 \put(2.5,0.0){\includegraphics[height=2cm,width=3.5cm]{gammatone_Q1.png}}
\end{picture}
\caption{
\label{fig:gammatones}
Left: Gammatone wavelet $\boldsymbol{\psi_{\gamma_1}}(t)$ with a quality factor of $Q=4$.
Right: Gammatone wavelet $\boldsymbol{\psi_{\gamma_2}}(t)$ with a quality factor of $Q=1$.
Blue and red oscillations represent the real and imaginary parts. The orange envelope represents
the complex modulus.}
\end{center}
\end{figure}

We define a wavelet filter bank $\{\psi_\lambda\}_{\lambda>0}$ by dilating a mother wavelet $\psi$ according to
\begin{equation}
	\psi_\lambda(t) = \lambda \psi(\lambda t).
\end{equation}
The mother wavelet $\psi$ is assumed to be analytic, that is with a zero Fourier transform for negative frequencies. In addition, we will the Fourier transform of $\psi$ to be centered around $1$. Consequently, $\psi_\lambda$ is centered at the frequency $\lambda$. A function $\psi$ that fulfills these criteria is the analytic gamma wavelet, illustrated in Figure \ref{fig:gammatones}. Its form is given explicitly by
\begin{equation}
	\psi(t) = ???
\end{equation}
We shall have use for wavelets of different quality factors $Q$. To begin with, we shall take $Q = 4$.

Given a signal $x$, we decompose it using the wavelet filter bank to obtain
\begin{equation}
	x \ast \psi_\lau(t) \quad \mathrm{for~}\lau>0,
\end{equation}
known as the wavelet decomposition of $x$. The dilation structure of the wavelet filter bank means that we do not need to sample $\lau$ continuously. Rather, it is sufficient to sample $\lau$ as $2^{j/Q}$, where $Q$ is the quality factor of the mother wavelet $\psi$. This means that we sample uniformly in log-frequency $\log \lau$.

The wavelet decomposition itself is very sensitive to time-shifting and time-warping, which can be reduced by taking the complex modulus. The result is known as the wavelet scalogram and we denote it by
\begin{equation}
	x_1(t, \log \lau) = | x \ast \psi_\lau(t) |.
\end{equation}
A sample scalogram is given in Figure \ref{fig:scalogram}.

The scalogram provides a useful representation of the time-frequency content of a signal. At a given point $(t, \log \lau)$, it gives the intensity of $x$ at time $t$ and log-frequency $\log \lau_1$. However, it does not have the desired invariance and stability properties. To achieve this, we average the scalogram in time using a lowpass filter $\phi_T(t)$ of duration $T$ to give
\begin{align}
	\nonumber
	S_1 x(t, \log \lau) &= x_1(\cdot, \log \lau) \ast \phi_T(t) \\
	&= | x \ast \psi_\lau | \ast \phi_T(t).
\end{align}
In our configuration $\phi_T$ is given by a Gabor filter centered at frequency $0$ with the desired bandwidth $T$ in time. The coefficients $S_1 x$ are known as first-order time scattering coefficients and are comparable to the commonly used mel-frequency spectrogram coefficients \cite{davis-mermelstein}.

The averaging by $\phi_T$ loses fine-scale structre in the scalogram $x_1$. To recover this, we calculate a second wavelet decomposition, this on the scalogram, along the time axis. Instead of the quality factor $Q = 4$ used in the first decomposition, we now use $Q = 1$. As before, we compute the complex modulus and obtain
\begin{align}
	\nonumber
	x_2(t, \log \lau, \log \lad) &= x_1(\cdot, \log \lau) \ast \psi_\lad(t) \\
	&= |\,| x \ast \psi_\lau | \ast \psi_\lad (t) |.
\end{align}
This second-order wavelet scalogram describes the modulation structure of the frequency band centered at $\log \lau$ of the first-order scalogram $x_1$. It is therefore closely related to modulation spectrograms \cite{atlas}, but are defined using wavelet decompositions instead of short-time Fourier transforms.

Again, to obtain invariance, the second-order scalogram $x_2$ is averaged in time using the lowpass filter $\phi_T$ to give
\begin{align}
	\nonumber
	S_2 x(t, \log \lau, \log \lad) &= x_2(\cdot, \log \lau, \log \lad) \\
	&= |\,| x \ast \psi_\lau | \ast \psi_\lad | \ast \phi_T(t),
\end{align}
which are known as second-order time scattering coefficients. Like modulation spectrograms, these coefficients provide information on the modulation structure of the signal $x$ at log-frequency $\log \lau$, but does so in a stable manner due to the wavelet construction. In this way, they are more closely related to constant-Q averaged modulation spectrograms \cite{ellis-mcdermott}. We note that the above procedure can be continued for third- and higher-order scattering coefficients, but that for most applications, first- and second-order coefficients suffice.

Concatenating all the first-order scattering coefficients into one vector
\begin{equation}
	S_1x(t) = \{S_1x(t, \log \lau)\}_{\lau>0},
\end{equation}
and doing the same for the second-order coefficients
\begin{equation}
	S_2x(t) = \{S_2x(t, \log \lau, \log \lad\}_{\lau>0, \lad>0},
\end{equation}
we can combine all of them into one scattering vector at time $t$
\begin{equation}
	Sx(t) = \{S_1x(t), S_2x(t)\}.
\end{equation}
It is important here to remark that, although the above formulas cover continuous domains in $t$, $\log \lau$, and $\log \lad$, these variables can all be sampled discretely without great loss of information. As mentioned earlier, $\log \lau$ and $\log \lad$ can be sampled uniformly with a step proportional to $1/Q$. In addition, the lowpass nature of the scalogram $x_1$ in time ensures that many coefficients in $x_2$ will be negligible for large values of $\log \lad$. As a result, these can be safely excluded from the transform. Finally, the lowpass filtering by $\phi_T$ ensures that we can sample the final scattering vector $Sx$ along multiples of $T$ in time.

\section{Scattering post-processing}

Instead of feeding the raw scattering vectors into the SVM classifier, we process them to facilitate model building by reducing their dynamic range and standardizing their variability. Specifically, we first compute the log-scattering coefficients by taking the logarithm of each value in the scattering vector to get
\begin{equation}
	\log S_1 x(t, \log \lau) = \log \left( | x \ast \psi_\lau | \ast \phi_T(t) \right)
\end{equation}
in the first order and
\begin{equation}
	\log S_2 x(t, \log \lau, \log \lad) = \log \left( |\,| x \ast \psi_\lau | \ast \psi_\lad | \ast \phi_T(t) \right)
\end{equation}
in the second order. These are combined across all log-frequencies $\log \lau$ and $\log \lad$ as before to yield a log-scattering vector $\log Sx(t)$.

The log-scattering coefficients are better suited for audio classification since audio amplitudes can vary across several orders of magnitude without significantly changing the content of the signal. This is often characterized as the Weber-Fechner law in psychoacoustics.

In addition, we diagonally standardize the coefficients to have mean zero and unit variance. To do this for our train-test splits, we calculate the mean and variance for each scattering coefficient across our training data and then use this to standardize both the training and testing data for the current split. This helps improve the conditioning of the SVM training since all values are in the same numerical range.

\section{Data augmentation}

The audio recordings provided for the scene classification challenge consist of a left and a right channel. As such, for each localized audio source in a recording, there is some variability depending on its relative location with respect to the microphone. This variability should have no bearing on the classification of the recording, so we would like to ensure invariance with respect to this relative orientation.

One approach is to simple average the left and right signals. If these are denoted by $x_L$ and $x_R$, respectively, we would thus have
\begin{equation}
	x_M(t) = \frac{1}{2} x_L(t) + \frac{1}{2} x_R(t),
\end{equation}
where $x_M$ is the mixed signal. Unfortunately, this emphasizes signals that are evenly mixed between left and right -- that is, signals that are perfectly centered in front of or behind the microphone -- at the expense of signals that are located only on the left and the right. Indeed, if $x_L$ is zero and $x_R$ contains the entire signal, the resulting mixed signal $x_M$ will have a lower amplitude.

To reduce this center bias, we augment the training data by including other mixed signals given by
\begin{equation}
	x_\alpha(t) = \frac{1-\alpha}{2} x_L(t) + \frac{1+\alpha}{2} x_R(t),
\end{equation}
where $\alpha$ takes values $-1$, $-1/2$, $0$, $1/2$, $1$. Note that our previous signal $x_M$ corresponds to $\alpha = 0$. This augmented training set thus simulates different localizations of the audio sources, allowing the classifier to learn invariance with respect to this parameter. At testing time, only the center mix ($\alpha = 0$) is used to calculate the scattering vector is fed into the classifier.

\section{Discussion}

\begin{table}[!htbp]
\centering
\caption{
Cross-validation results.
\label{table:single-label-durations}}
\begin{tabular}{llll}
\toprule
Scene & Baseline & Temporal scattering & Temporal scattering \\
           &               &  (1 azimuth)  & (5 azimuths) \\
\midrule
beach & 72.0 $\pm$ 19.0 & & 84.9 $\pm$ 11.7 \\

bus & 62.0 $\pm$ 19.6 & & 91.3 $\pm$ 14.4 \\

cafe/restaurant & 83.9 $\pm$ 12.1 & & 57.1 $\pm$ 20.5 \\

car & 75.7 $\pm$ 17.7 & & 93.7 $\pm$  \phantom{0}6.3 \\

city center & 85.6 $\pm$ 18.5 & & 92.8 $\pm$  \phantom{0}8.9 \\

forest path & 65.9 $\pm$ 26.5 & & 96.4 $\pm$  \phantom{0}7.2 \\

grocery store & 76.6 $\pm$ 22.3 & & 84.3 $\pm$ 15.6 \\

home & 79.5 $\pm$ 18.6 & & 64.2 $\pm$ 26.3 \\

library & 61.3 $\pm$ 30.5 & & 81.1 $\pm$  \phantom{0}7.5 \\

metro station & 85.3 $\pm$ 18.0 & & 98.7 $\pm$  \phantom{0}2.7 \\

office & 91.1 $\pm$ \phantom{0}7.9 & & 86.1 $\pm$ 27.8 \\

park & 24.5 $\pm$ 15.6 & & 75.6 $\pm$ 10.5 \\

residential area & 75.4 $\pm$ 29.1 & & 55.8 $\pm$ 20.2 \\

train & 36.7 $\pm$ 10.8 & & 57.1 $\pm$ 15.3 \\

tram & 89.5 $\pm$ 17.5& & 86.4 $\pm$ 11.7 \\

\bottomrule

average & 71.3 $\pm$  \phantom{0}3.8 & & 80.4 $\pm$  \phantom{0}3.5
\end{tabular}
\end{table}

\section{Conclusion}
This technical report presents 

\bibliographystyle{IEEEtran}
\bibliography{Lostanlen_dcase2016}

\end{sloppy}

\end{document}


